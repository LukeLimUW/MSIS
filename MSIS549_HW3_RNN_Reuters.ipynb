{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSIS579-HW3-RNN-Reuters.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2fyLhUMQlyH",
        "colab_type": "text"
      },
      "source": [
        "# MSIS 579 HW3 RNN to Classify Reuters Topics\n",
        "\n",
        "In this homework, we will train a recurrent neural network to Classify Reuters newswires into 46 Topics.\n",
        "\n",
        "Dataset of 11,228 newswires from Reuters, labeled over 46 topics. As with the IMDB dataset, each wire is encoded as a sequence of word indexes (same conventions)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3Y8ZHFGR1uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.14\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import keras\n",
        "keras.__version__\n",
        "\n",
        "!pip install numpy==1.16.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvtq164jRPNz",
        "colab_type": "text"
      },
      "source": [
        "## Load Reuters Dataset\n",
        "\n",
        "First let's load the Reuters dataset. Please refer to [this API page](https://keras.io/datasets/#reuters-newswire-topics-classification) for details on how to load the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbt21X3mQjZw",
        "colab_type": "code",
        "outputId": "f7067863-bfb0-4baa-cede-80465e171737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras.datasets import reuters\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "max_words = 10000\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words, test_split=0.2)\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd7wneSMSTpS",
        "colab_type": "text"
      },
      "source": [
        "## Task 1: Fully Connected Neural Networks\n",
        "\n",
        "In this task, we will learn a word embedding layer as well as fully connected layers to classify Reuters newwires. Please refer to the lab code from lesson 4. Watch out the overfitting. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7OPafLXRsnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9__yxAHUSrb",
        "colab_type": "text"
      },
      "source": [
        "## Task 2: RNN/LSTM\n",
        "Now, we have a fully connected neural networks trained for prediction topics in Reuters data. In this task, we will swap out the fully connect layers and replace with a more powerful RNN layers (LSTM, GRU). Try experiment with different RNN layers and see if they can help improve the model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXGH40siUTT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asCa299TUV7N",
        "colab_type": "text"
      },
      "source": [
        "## Task 3: Use a Pre-trained Word Embedding\n",
        "\n",
        "In this task, instead of learning the word embedding layer from scratch, we apply a pre-trained word embedding layer and only use the classification base for reuters data. Please refer to the [API](https://keras.io/examples/pretrained_word_embeddings/) for different pre-trained word embedding.\n",
        "\n",
        "Does the pre-trained word embedding help improve the model prediction?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkQprFAyU-0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}